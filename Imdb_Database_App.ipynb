{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Practicum II - Movie Database Applicaton\n",
    "### Collaborators: Abasamia Akpan, Rebecca Brent and Alessia Pizzoccheri\n",
    "\n",
    "This Notebook provides context, documentation and sample code for a Database Application using IMBd datasets; for clarity, this document has been divided into the following sections:\n",
    "\n",
    "### 1. Introduction\n",
    "### 2. Assumptions\n",
    "### 3. Logical Models\n",
    "### 4. Database and Relations DefinitionÂ¶\n",
    "### 1. Introduction\n",
    "#### 1.1. Looking at the data\n",
    "In this section, we analyze and deconstruct the various data sets found on the IMBd page; data is organized in seven TSV files, specifically:\n",
    "\n",
    "Title AKAs\n",
    "Title Basics\n",
    "Title Episodes\n",
    "Title Ratings\n",
    "Title Crew\n",
    "Name Basics\n",
    "Title Principles Our first step is to establish relationships between each data set and identify a primary key (PK) on each table. Since no information was provided regarding the role of columns, we devised a solution to find unique identifiers within each data set; that is, for each table we compare the total number of rows against the total number of unique values for a given column.\n",
    "1.2 Establishing PKs\n",
    "Following the system aforementioned, we identified the following primary keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: pip is being invoked by an old script wrapper. This will fail in a future version of pip.\n",
      "Please see https://github.com/pypa/pip/issues/5599 for advice on fixing the underlying issue.\n",
      "To avoid this problem you can invoke Python with '-m pip' instead of running pip directly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: prettytable in /Users/apizzoccheri/opt/anaconda3/lib/python3.8/site-packages (1.0.1)\n",
      "Requirement already satisfied: setuptools in /Users/apizzoccheri/opt/anaconda3/lib/python3.8/site-packages (from prettytable) (49.2.0.post20200714)\n",
      "Requirement already satisfied: wcwidth in /Users/apizzoccheri/opt/anaconda3/lib/python3.8/site-packages (from prettytable) (0.2.5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: pip is being invoked by an old script wrapper. This will fail in a future version of pip.\n",
      "Please see https://github.com/pypa/pip/issues/5599 for advice on fixing the underlying issue.\n",
      "To avoid this problem you can invoke Python with '-m pip' instead of running pip directly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mysql-connector-python in /Users/apizzoccheri/opt/anaconda3/lib/python3.8/site-packages (8.0.22)\n",
      "Requirement already satisfied: protobuf>=3.0.0 in /Users/apizzoccheri/opt/anaconda3/lib/python3.8/site-packages (from mysql-connector-python) (3.13.0)\n",
      "Requirement already satisfied: setuptools in /Users/apizzoccheri/opt/anaconda3/lib/python3.8/site-packages (from protobuf>=3.0.0->mysql-connector-python) (49.2.0.post20200714)\n",
      "Requirement already satisfied: six>=1.9 in /Users/apizzoccheri/opt/anaconda3/lib/python3.8/site-packages (from protobuf>=3.0.0->mysql-connector-python) (1.15.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: pip is being invoked by an old script wrapper. This will fail in a future version of pip.\n",
      "Please see https://github.com/pypa/pip/issues/5599 for advice on fixing the underlying issue.\n",
      "To avoid this problem you can invoke Python with '-m pip' instead of running pip directly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in /Users/apizzoccheri/opt/anaconda3/lib/python3.8/site-packages (4.47.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: pip is being invoked by an old script wrapper. This will fail in a future version of pip.\n",
      "Please see https://github.com/pypa/pip/issues/5599 for advice on fixing the underlying issue.\n",
      "To avoid this problem you can invoke Python with '-m pip' instead of running pip directly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pymysql in /Users/apizzoccheri/opt/anaconda3/lib/python3.8/site-packages (0.10.1)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import pip\n",
    "pip.main(['install','prettytable'])\n",
    "pip.main(['install','mysql-connector-python'])\n",
    "pip.main(['install','tqdm'])\n",
    "pip.main(['install','pymysql'])\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection to MySQL DB successful\n",
      "Database created successfully\n",
      "Connection to MySQL DB successful\n",
      "1046 (3D000): No database selected\n",
      "1046 (3D000): No database selected\n",
      "1046 (3D000): No database selected\n",
      "1046 (3D000): No database selected\n",
      "1046 (3D000): No database selected\n",
      "1046 (3D000): No database selected\n",
      "1046 (3D000): No database selected\n",
      "1046 (3D000): No database selected\n",
      "1046 (3D000): No database selected\n",
      "1046 (3D000): No database selected\n",
      "1046 (3D000): No database selected\n",
      "1046 (3D000): No database selected\n",
      "1046 (3D000): No database selected\n",
      "1046 (3D000): No database selected\n",
      "1046 (3D000): No database selected\n",
      "1046 (3D000): No database selected\n",
      "1046 (3D000): No database selected\n",
      "1046 (3D000): No database selected\n",
      "1046 (3D000): No database selected\n",
      "1046 (3D000): No database selected\n",
      "1046 (3D000): No database selected\n",
      "1046 (3D000): No database selected\n",
      "1046 (3D000): No database selected\n"
     ]
    }
   ],
   "source": [
    "import mysql.connector\n",
    "from prettytable import PrettyTable \n",
    "from prettytable import from_csv\n",
    "from mysql.connector import Error\n",
    "\n",
    "# constant variables\n",
    "BATCH_SIZE = 100000\n",
    "\n",
    "# global variables\n",
    "mydb = None\n",
    "cursor = None\n",
    "\n",
    "def create_connection_nodb(host_name, user_name, user_password):\n",
    "    \"\"\" create a connection to mysql host\n",
    "    :param host_name: string host name (ie. \"localhost\")\n",
    "    :param user_name: string username (ie. \"root\")\n",
    "    :param user_password: string the password to connect to mysql\n",
    "    :return: connection object\n",
    "    \"\"\"\n",
    "    connection = None\n",
    "    try:\n",
    "        connection = mysql.connector.connect(\n",
    "            host=host_name,\n",
    "            user=user_name,\n",
    "            passwd=user_password\n",
    "        )\n",
    "        print(\"Connection to MySQL DB successful\")\n",
    "    except Error as e:\n",
    "        print(f\"The error '{e}' occurred\")\n",
    "\n",
    "    return connection\n",
    "\n",
    "def create_database(connection, db_name):\n",
    "    \"\"\" create a database \n",
    "    :param connection: Connection object\n",
    "    :param db_name: name of database in form of string\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    cursor = connection.cursor()\n",
    "    try:\n",
    "        query = \"CREATE DATABASE IF NOT EXISTS \" + db_name\n",
    "        cursor.execute(query)\n",
    "        print(\"Database created successfully\")\n",
    "    except Error as e:\n",
    "        print(f\"The error '{e}' occurred\")\n",
    "        \n",
    "def create_connection(host_name, user_name, user_password, db_name):\n",
    "    \"\"\" create a connection to the (possibly newly created) database\n",
    "    :param host_name: string host name (ie. \"localhost\")\n",
    "    :param user_name: string username (ie. \"root\")\n",
    "    :param user_password: string the password to connect to mysql\n",
    "    :param db_name: string name of database \n",
    "    :return: connection object\n",
    "    \"\"\"\n",
    "    try:\n",
    "        mydb = mysql.connector.connect(\n",
    "            host=host_name,\n",
    "            user=user_name,\n",
    "            passwd=user_password,\n",
    "            database=db_name\n",
    "        )\n",
    "        print(\"Connection to MySQL DB successful\")\n",
    "    except Error as e:\n",
    "        print(f\"The error '{e}' occurred\")\n",
    "\n",
    "    return mydb\n",
    "\n",
    "def create_table(conn, create_table_sql):\n",
    "    \"\"\" create a table from the create_table_sql statement\n",
    "    :param conn: Connection object\n",
    "    :param create_table_sql: a CREATE TABLE statement\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    try:\n",
    "        c = conn.cursor()\n",
    "        c.execute(create_table_sql)\n",
    "        table_name = create_table_sql.split(\" \")[5].split(\"(\")[0]\n",
    "        print(\"Successfully created table: \" + table_name)\n",
    "    except Error as e:\n",
    "        print(e)\n",
    "        \n",
    "def main():\n",
    "    \n",
    "    database = \"name_basics_preprocessed_new\"\n",
    "    host_name = \"localhost\"\n",
    "    user_name = \"root\"\n",
    "    user_password = \"alupizzo92\"\n",
    "    \n",
    "    create_table_titlebasics = \"\"\"CREATE TABLE IF NOT EXISTS titlebasics(\n",
    "                                    tconst VARCHAR(1000) PRIMARY KEY,\n",
    "                                    titleType VARCHAR(1000),\n",
    "                                    primaryTitle VARCHAR(1000),\n",
    "                                    originalTitle VARCHAR(1000),\n",
    "                                    isAdult BOOLEAN,\n",
    "                                    startYear DATE,\n",
    "                                    endYear DATE,\n",
    "                                    runTimeMinutes TIME)\"\"\"\n",
    "    \n",
    "    create_table_titleratings = \"\"\"CREATE TABLE IF NOT EXISTS titleratings(\n",
    "                                    tconst VARCHAR(1000) PRIMARY KEY,\n",
    "                                    averageRating FLOAT,\n",
    "                                    numVotes INT,\n",
    "                                    FOREIGN KEY (tconst) REFERENCES titlebasics(tconst))\"\"\"\n",
    "\n",
    "\n",
    "    create_table_titleepisodes = \"\"\"CREATE TABLE IF NOT EXISTS titleepisodes(\n",
    "                                    tconst VARCHAR(1000) PRIMARY KEY,\n",
    "                                    seasonNumber INT,\n",
    "                                    episodeNumber INT,\n",
    "                                    parentTconst VARCHAR(1000),\n",
    "                                    FOREIGN KEY (parentTconst) REFERENCES titlebasics(tconst))\"\"\"\n",
    "\n",
    "    create_table_titleAKAs = \"\"\"CREATE TABLE IF NOT EXISTS titleAKAs(\n",
    "                                AKAsID INT AUTO_INCREMENT PRIMARY KEY,\n",
    "                                titleID VARCHAR(1000),\n",
    "                                ordering INT,\n",
    "                                title VARCHAR(1000),\n",
    "                                region VARCHAR(1000),\n",
    "                                language VARCHAR(1000),\n",
    "                                isoriginaltitle BOOLEAN,\n",
    "                                FOREIGN KEY (titleID) REFERENCES titlebasics(tconst))\"\"\"\n",
    "\n",
    "    create_table_namebasics = \"\"\"CREATE TABLE IF NOT EXISTS namebasics(\n",
    "                                nconst VARCHAR(1000) PRIMARY KEY,\n",
    "                                primaryname VARCHAR(1000),\n",
    "                                birthyear DATE,\n",
    "                                deathyear DATE,\n",
    "                                noofmovies INT,\n",
    "                                age INT,\n",
    "                                currentdate DATE)\"\"\"\n",
    "    \n",
    "    create_table_principals = \"\"\"CREATE TABLE IF NOT EXISTS principals(\n",
    "                                principalsID INT AUTO_INCREMENT PRIMARY KEY,\n",
    "                                tconst VARCHAR(1000),\n",
    "                                ordering INT,\n",
    "                                category VARCHAR(1000),\n",
    "                                job VARCHAR(1000),\n",
    "                                nconst VARCHAR(1000),\n",
    "                                FOREIGN KEY (tconst) REFERENCES titlebasics(tconst),\n",
    "                                FOREIGN KEY (nconst) REFERENCES namebasics(nconst))\"\"\"\n",
    "    \n",
    "    create_table_titlecrew = \"\"\"CREATE TABLE IF NOT EXISTS titlecrew(\n",
    "                                crewid INT AUTO_INCREMENT PRIMARY KEY,\n",
    "                                tconst VARCHAR(1000) UNIQUE,\n",
    "                                FOREIGN KEY (tconst) REFERENCES titlebasics(tconst))\"\"\"\n",
    "    \n",
    "    create_table_characters = \"\"\"CREATE TABLE IF NOT EXISTS characters(\n",
    "                                characterID INT AUTO_INCREMENT PRIMARY KEY,\n",
    "                                name VARCHAR(1000) UNIQUE)\"\"\"\n",
    "    \n",
    "    create_table_writers = \"\"\"CREATE TABLE IF NOT EXISTS writers(\n",
    "                                writerID INT AUTO_INCREMENT PRIMARY KEY,\n",
    "                                name VARCHAR(1000) UNIQUE)\"\"\"\n",
    "    \n",
    "    create_table_directors = \"\"\"CREATE TABLE IF NOT EXISTS directors(\n",
    "                                directorID INT AUTO_INCREMENT PRIMARY KEY,\n",
    "                                name VARCHAR(1000) UNIQUE)\"\"\"\n",
    "    \n",
    "    create_table_genres = \"\"\"CREATE TABLE IF NOT EXISTS genres(\n",
    "                                genreID INT AUTO_INCREMENT  PRIMARY KEY,\n",
    "                                genre VARCHAR(1000) UNIQUE)\"\"\"\n",
    "    \n",
    "    create_table_knownfortitles = \"\"\"CREATE TABLE IF NOT EXISTS knownfortitles(\n",
    "                                knownfortitlesID INT AUTO_INCREMENT PRIMARY KEY,\n",
    "                                titles VARCHAR(1000) UNIQUE)\"\"\"\n",
    "    \n",
    "    create_table_primaryprofession = \"\"\"CREATE TABLE IF NOT EXISTS primaryprofession(\n",
    "                                primaryprofessionID INT AUTO_INCREMENT PRIMARY KEY,\n",
    "                                profession VARCHAR(1000) UNIQUE)\"\"\"\n",
    "    \n",
    "    create_table_types = \"\"\"CREATE TABLE IF NOT EXISTS types(\n",
    "                                typeID INT AUTO_INCREMENT  PRIMARY KEY,\n",
    "                                type VARCHAR(1000) UNIQUE)\"\"\"\n",
    "    \n",
    "    create_table_attributes = \"\"\"CREATE TABLE IF NOT EXISTS attributes(\n",
    "                                attributeID INT AUTO_INCREMENT PRIMARY KEY,\n",
    "                                attribute VARCHAR(1000) UNIQUE)\"\"\"\n",
    "    \n",
    "    create_table_genretitlebasics = \"\"\"CREATE TABLE IF NOT EXISTS genretitlebasics(\n",
    "                                titlebasicsID VARCHAR(1000),\n",
    "                                genreID INT,\n",
    "                                PRIMARY KEY (titlebasicsID, genreID),\n",
    "                                FOREIGN KEY (titlebasicsID) REFERENCES titlebasics(tconst),\n",
    "                                FOREIGN KEY (genreID) REFERENCES genres(genreID))\"\"\"\n",
    "    \n",
    "    create_table_crewdirectors = \"\"\"CREATE TABLE IF NOT EXISTS crewdirectors(\n",
    "                                crewid INT,\n",
    "                                directorid INT,\n",
    "                                PRIMARY KEY (crewid ,directorid),\n",
    "                                FOREIGN KEY (crewid) REFERENCES titlecrew(crewid),\n",
    "                                FOREIGN KEY (directorid) REFERENCES directors(directorID))\"\"\"\n",
    "    \n",
    "    create_table_crewwriters = \"\"\"CREATE TABLE IF NOT EXISTS crewwriters(\n",
    "                                crewid INT,\n",
    "                                writerid INT,\n",
    "                                PRIMARY KEY (crewid, writerid),\n",
    "                                FOREIGN KEY (crewid) REFERENCES titlecrew(crewid),\n",
    "                                FOREIGN KEY (writerid) REFERENCES writers(writerid))\"\"\"\n",
    "    \n",
    "    create_table_principalscharacters = \"\"\"CREATE TABLE IF NOT EXISTS principalscharacters(\n",
    "                                principalsid INT,\n",
    "                                characterid INT,\n",
    "                                PRIMARY KEY (principalsid, characterid),\n",
    "                                FOREIGN KEY (principalsid) REFERENCES principals(principalsID),\n",
    "                                FOREIGN KEY (characterid) REFERENCES characters(characterid))\"\"\"\n",
    "    \n",
    "    create_table_AKAattributes = \"\"\"CREATE TABLE IF NOT EXISTS AKAattributes(\n",
    "                                akasid INT,\n",
    "                                attributeid INT,\n",
    "                                PRIMARY KEY (akasid, attributeid),\n",
    "                                FOREIGN KEY (akasid) REFERENCES titleAKAs(AKAsID),\n",
    "                                FOREIGN KEY (attributeid) REFERENCES attributes(attributeid))\"\"\"\n",
    "    \n",
    "    create_table_AKAtype = \"\"\"CREATE TABLE IF NOT EXISTS AKAtype(\n",
    "                                akasid INT,\n",
    "                                typeid INT,\n",
    "                                PRIMARY KEY (akasid, typeid),\n",
    "                                FOREIGN KEY (akasid) REFERENCES titleAKAs(AKAsID),\n",
    "                                FOREIGN KEY (typeid) REFERENCES type(typeid))\"\"\"\n",
    "    \n",
    "    create_table_primaryprofessiontitlenames = \"\"\"CREATE TABLE IF NOT EXISTS primaryprofessiontitlenames(\n",
    "                                primaryprofessionid INT,\n",
    "                                namebasicsid VARCHAR(255),\n",
    "                                PRIMARY KEY (primaryprofessionid, namebasicsid),\n",
    "                                FOREIGN KEY (primaryprofessionid) REFERENCES primaryprofession(primaryprofessionid),\n",
    "                                FOREIGN KEY (namebasicsid) REFERENCES namebasics(nconst))\"\"\"\n",
    "    \n",
    "    create_table_knownfortitlenames = \"\"\"CREATE TABLE IF NOT EXISTS knownfortitlenames(\n",
    "                                namebasicsid VARCHAR(255),\n",
    "                                knownfortitlesid INT,\n",
    "                                PRIMARY KEY (namebasicsid, knownfortitlesid),\n",
    "                                FOREIGN KEY (namebasicsid) REFERENCES namebasics(nconst),\n",
    "                                FOREIGN KEY (knownfortitlesid) REFERENCES knownfortitles(knownfortitlesid))\"\"\"\n",
    "    \n",
    "    conn = create_connection_nodb(host_name, user_name, user_password)\n",
    "    \n",
    "    # create database object if not already created and then connect the cursor to it\n",
    "    if conn is not None:\n",
    "        create_database(conn, database)\n",
    "        create_connection(host_name, user_name, user_password, database)\n",
    "\n",
    "        # create tables\n",
    "        if conn is not None:\n",
    "            # create Title Basics table\n",
    "            create_table(conn, create_table_titlebasics)\n",
    "\n",
    "            # create Title Ratings table\n",
    "            create_table(conn, create_table_titleratings)\n",
    "            \n",
    "            # create title episodes table\n",
    "            create_table(conn, create_table_titleepisodes)\n",
    "            \n",
    "            # create title AKAs table\n",
    "            create_table(conn, create_table_titleAKAs)\n",
    "            \n",
    "            # create name basics table\n",
    "            create_table(conn, create_table_namebasics)\n",
    "            \n",
    "            # create principals table\n",
    "            create_table(conn, create_table_principals)\n",
    "            \n",
    "            # create title crew table\n",
    "            create_table(conn, create_table_titlecrew)\n",
    "            \n",
    "            # create characters table\n",
    "            create_table(conn,create_table_characters)\n",
    "            \n",
    "            # create writers table\n",
    "            create_table(conn,create_table_writers)\n",
    "            \n",
    "            # create directors table\n",
    "            create_table(conn,create_table_directors)\n",
    "            \n",
    "            # create genres table\n",
    "            create_table(conn,create_table_genres)\n",
    "            \n",
    "            # create known for titles table\n",
    "            create_table(conn,create_table_knownfortitles)\n",
    "            \n",
    "            # create primary profession table\n",
    "            create_table(conn,create_table_primaryprofession)\n",
    "            \n",
    "            # create type table\n",
    "            create_table(conn,create_table_types)\n",
    "            \n",
    "            # create attributes table\n",
    "            create_table(conn,create_table_attributes)\n",
    "            \n",
    "            # create genre title basics table\n",
    "            create_table(conn, create_table_genretitlebasics)\n",
    "            \n",
    "            # create crew directors table\n",
    "            create_table(conn,create_table_crewdirectors)\n",
    "            \n",
    "            # create crew writers table\n",
    "            create_table(conn,create_table_crewwriters)\n",
    "            \n",
    "            # create principals characters table\n",
    "            create_table(conn, create_table_principalscharacters)\n",
    "            \n",
    "            # create AKA Attributes table\n",
    "            create_table(conn, create_table_AKAattributes)\n",
    "            \n",
    "            # create AKA Type table\n",
    "            create_table(conn, create_table_AKAtype)\n",
    "            \n",
    "            # create Primary Profession Title Names table\n",
    "            create_table(conn, create_table_primaryprofessiontitlenames)\n",
    "            \n",
    "            # create known for title names table\n",
    "            create_table(conn, create_table_knownfortitlenames)\n",
    "                \n",
    "        else:\n",
    "            print(\"Error! cannot create the database connection.\")\n",
    "    \n",
    "    else:\n",
    "        print(\"Error! Cannot create the MySQL connection.\")\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SQL Communication Helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlalchemy\n",
    "database_username = 'root'\n",
    "database_password = 'alupizzo92'\n",
    "database_ip       = 'localhost'\n",
    "database_name     = 'imbd_application'\n",
    "database_connection = sqlalchemy.create_engine('mysql+mysqlconnector://{0}:{1}@{2}/{3}'.\n",
    "                                               format(database_username, database_password, \n",
    "                                                      database_ip, database_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define load_dataframe function\n",
    "def load_dataframe(data_frame,table_name):\n",
    "    data_frame_new = data_frame\n",
    "    data_frame_new.to_sql(table_name,con=database_connection, if_exists='append',index=False)\n",
    "\n",
    "# define batch function\n",
    "def batch(iterable, n=1):\n",
    "    l = len(iterable)\n",
    "    for ndx in range(0, l, n):\n",
    "        yield iterable[ndx:min(ndx + n, l)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Title Basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apizzoccheri/opt/anaconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3071: DtypeWarning: Columns (5) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "# read title basic file\n",
    "title_basics = pd.read_csv('title.basics.tsv', delimiter='\\t',encoding='utf-8')\n",
    "# UNCOMMENT TO DISPLAY ALL DATA\n",
    "# title_basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess the title basics data\n",
    "def preprocess_dataframe_title_basics(data_frame):\n",
    "    title_basics_new_series = data_frame\n",
    "\n",
    "    b = pd.to_datetime(title_basics_new_series['runtimeMinutes'], errors='coerce', format='%M')\n",
    "\n",
    "    b.to_frame().runtimeMinutes\n",
    "    df_1 = pd.DataFrame(dict(time_stamps = b)) \n",
    "    \n",
    "    # convert time stamp to minutes\n",
    "    df_1['runtimeMinutes'] = df_1['time_stamps'].dt.minute\n",
    "    title_basics_new_series = title_basics_new_series.drop(['runtimeMinutes'],axis=1)\n",
    "    title_basics_new_series['runtimeMinutes'] = df_1['runtimeMinutes']\n",
    "    title_basics_new_frame_transpose = title_basics_new_series.astype({'isAdult': 'int32'})\n",
    "    title_basics_new_frame_transpose[\"isAdult\"]=title_basics_new_frame_transpose.isAdult.mask(title_basics_new_frame_transpose.isAdult > 1,1)\n",
    "\n",
    "    #needs to be fixed\n",
    "    title_basics_new_frame_transpose['startYear'] = pd.to_datetime(title_basics.startYear, errors='coerce', format='%Y')\n",
    "    title_basics_new_frame_transpose['endYear']= pd.to_datetime(title_basics.endYear, errors='coerce', format='%Y')\n",
    "\n",
    "    title_basics_new_frame_transpose=title_basics_new_frame_transpose.drop(['genres'],axis=1)\n",
    "\n",
    "    # constuct new row\n",
    "    new_row = {\n",
    "        'tconst':None, \n",
    "        'titleType':None, \n",
    "        'primaryTitle':None,\n",
    "        'originalTitle':None,\n",
    "        'isAdult':None, \n",
    "        'startYear':None,\n",
    "        'endYear':None,\n",
    "        'runtimeMinutes':None         \n",
    "    } \n",
    "  \n",
    "    title_basics_new_frame_transpose = title_basics_new_frame_transpose.append(new_row, ignore_index=True)\n",
    "    return title_basics_new_frame_transpose\n",
    "\n",
    "title_basics_preprocessed = preprocess_dataframe_title_basics(title_basics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total size of data:  7300502\n"
     ]
    }
   ],
   "source": [
    "# print total count of data rows\n",
    "print('Total size of data: ', len(title_basics_preprocessed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|ââââââââââ| 74/74 [03:11<00:00,  2.59s/it]\n"
     ]
    }
   ],
   "source": [
    "length = len(title_basics_preprocessed) // BATCH_SIZE + 1\n",
    "\n",
    "for chunk in tqdm(batch(title_basics_preprocessed, BATCH_SIZE), total = length):\n",
    "    # call helper function\n",
    "    load_dataframe(chunk, 'titlebasics')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Title ratings ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data from title ratings file\n",
    "title_ratings = pd.read_csv('title.ratings.tsv', delimiter='\\t',encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess the title ratings data\n",
    "def preprocess_dataframe_title_ratings(data_frame):\n",
    "    title_ratings_new_series = data_frame\n",
    "    \n",
    "    title_ratings_new_frame_avg_rating = title_ratings_new_series.astype({'averageRating': 'float'})\n",
    "    title_ratings_new_frame_avg_rating = title_ratings_new_series.astype({'numVotes': 'int32'})\n",
    "  \n",
    "    return title_ratings_new_frame_avg_rating\n",
    "\n",
    "title_ratings_preprocessed = preprocess_dataframe_title_ratings(title_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total size of data:  1086514\n"
     ]
    }
   ],
   "source": [
    "# print total count of data rows\n",
    "print('Total size of data: ', len(title_ratings_preprocessed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|ââââââââââ| 11/11 [00:14<00:00,  1.29s/it]\n"
     ]
    }
   ],
   "source": [
    "length = len(title_ratings_preprocessed) // BATCH_SIZE + 1\n",
    "\n",
    "for chunk in tqdm(batch(title_ratings_preprocessed, BATCH_SIZE), total = length):\n",
    "    load_dataframe(chunk, 'titleratings')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Title Episodes ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read title episodes data\n",
    "title_episodes = pd.read_csv('title.episode.tsv', delimiter='\\t',encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess the title episodes data\n",
    "def preprocess_dataframe_title_episodes(data_frame):\n",
    "    title_episodes_new_series=data_frame\n",
    "    title_episodes_coerce_seasonNum = pd.to_numeric(title_episodes_new_series['seasonNumber'], errors='coerce')\n",
    "    title_episodes_coerce_episodeNum = pd.to_numeric(title_episodes_new_series['episodeNumber'], errors='coerce')\n",
    "\n",
    "    df_1 = pd.DataFrame(dict(test_column_1 = title_episodes_coerce_seasonNum)) \n",
    "    df_2 = pd.DataFrame(dict(test_column_2 = title_episodes_coerce_episodeNum)) \n",
    "\n",
    "    df_1['seasonNumber'] = df_1['test_column_1']\n",
    "    df_2['episodeNumber'] = df_2['test_column_2']\n",
    "    \n",
    "    title_episodes_new_frame = title_episodes_new_series.drop(['seasonNumber'],axis=1)\n",
    "    title_episodes_new_frame = title_episodes_new_series.drop(['episodeNumber'],axis=1)\n",
    "    \n",
    "    title_episodes_new_frame['seasonNumber'] = df_1['seasonNumber']\n",
    "    title_episodes_new_frame['episodeNumber'] = df_2['episodeNumber']\n",
    "       \n",
    "    return title_episodes_new_frame\n",
    "\n",
    "title_episodes_preprocessed = preprocess_dataframe_title_episodes(title_episodes)\n",
    "title_episodes_preprocessed.tconst = title_episodes_preprocessed.tconst.mask(~title_episodes_preprocessed.tconst.isin(title_basics_preprocessed.tconst), None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total size of data:  5261727\n"
     ]
    }
   ],
   "source": [
    "# print total count of data rows\n",
    "print('Total size of data: ', len(title_episodes_preprocessed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|ââââââââââ| 53/53 [01:21<00:00,  1.53s/it]\n"
     ]
    }
   ],
   "source": [
    "length = len(title_episodes_preprocessed) // BATCH_SIZE +1\n",
    "\n",
    "for chunk in tqdm(batch(title_episodes_preprocessed, BATCH_SIZE), total = length):\n",
    "    # call helper function\n",
    "    load_dataframe(chunk, 'titleepisodes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Title Akas ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apizzoccheri/opt/anaconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3071: DtypeWarning: Columns (7) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "title_akas = pd.read_csv('title.akas.tsv', delimiter='\\t',encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>titleId</th>\n",
       "      <th>ordering</th>\n",
       "      <th>title</th>\n",
       "      <th>region</th>\n",
       "      <th>language</th>\n",
       "      <th>isOriginalTitle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>75588</th>\n",
       "      <td>tt0021006</td>\n",
       "      <td>1</td>\n",
       "      <td>Ja, der Himmel Ã¼ber Wien</td>\n",
       "      <td>AT</td>\n",
       "      <td>\\N</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78146</th>\n",
       "      <td>tt0021453</td>\n",
       "      <td>1</td>\n",
       "      <td>Tapping Toes</td>\n",
       "      <td>US</td>\n",
       "      <td>\\N</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87274</th>\n",
       "      <td>tt0023019</td>\n",
       "      <td>1</td>\n",
       "      <td>Hollywood on Parade</td>\n",
       "      <td>US</td>\n",
       "      <td>\\N</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97677</th>\n",
       "      <td>tt0024677</td>\n",
       "      <td>1</td>\n",
       "      <td>Tom's in Town</td>\n",
       "      <td>US</td>\n",
       "      <td>\\N</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174270</th>\n",
       "      <td>tt0036165</td>\n",
       "      <td>1</td>\n",
       "      <td>Missing Men</td>\n",
       "      <td>US</td>\n",
       "      <td>\\N</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20596836</th>\n",
       "      <td>tt7978886</td>\n",
       "      <td>1</td>\n",
       "      <td>State of Defacto</td>\n",
       "      <td>AM</td>\n",
       "      <td>\\N</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20981546</th>\n",
       "      <td>tt8206494</td>\n",
       "      <td>1</td>\n",
       "      <td>Blood for Dust</td>\n",
       "      <td>US</td>\n",
       "      <td>\\N</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21420340</th>\n",
       "      <td>tt8466868</td>\n",
       "      <td>1</td>\n",
       "      <td>Butaca</td>\n",
       "      <td>ES</td>\n",
       "      <td>\\N</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22287099</th>\n",
       "      <td>tt8982514</td>\n",
       "      <td>1</td>\n",
       "      <td>To The Bitter End</td>\n",
       "      <td>US</td>\n",
       "      <td>\\N</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23208015</th>\n",
       "      <td>tt9496006</td>\n",
       "      <td>1</td>\n",
       "      <td>Panther Brawl: A Documentary on the Masuk High...</td>\n",
       "      <td>US</td>\n",
       "      <td>\\N</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15361 rows Ã 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            titleId  ordering  \\\n",
       "75588     tt0021006         1   \n",
       "78146     tt0021453         1   \n",
       "87274     tt0023019         1   \n",
       "97677     tt0024677         1   \n",
       "174270    tt0036165         1   \n",
       "...             ...       ...   \n",
       "20596836  tt7978886         1   \n",
       "20981546  tt8206494         1   \n",
       "21420340  tt8466868         1   \n",
       "22287099  tt8982514         1   \n",
       "23208015  tt9496006         1   \n",
       "\n",
       "                                                      title region language  \\\n",
       "75588                              Ja, der Himmel Ã¼ber Wien     AT       \\N   \n",
       "78146                                          Tapping Toes     US       \\N   \n",
       "87274                                   Hollywood on Parade     US       \\N   \n",
       "97677                                         Tom's in Town     US       \\N   \n",
       "174270                                          Missing Men     US       \\N   \n",
       "...                                                     ...    ...      ...   \n",
       "20596836                                   State of Defacto     AM       \\N   \n",
       "20981546                                     Blood for Dust     US       \\N   \n",
       "21420340                                             Butaca     ES       \\N   \n",
       "22287099                                  To The Bitter End     US       \\N   \n",
       "23208015  Panther Brawl: A Documentary on the Masuk High...     US       \\N   \n",
       "\n",
       "          isOriginalTitle  \n",
       "75588                 NaN  \n",
       "78146                 NaN  \n",
       "87274                 NaN  \n",
       "97677                 NaN  \n",
       "174270                NaN  \n",
       "...                   ...  \n",
       "20596836              0.0  \n",
       "20981546              0.0  \n",
       "21420340              0.0  \n",
       "22287099              0.0  \n",
       "23208015              0.0  \n",
       "\n",
       "[15361 rows x 6 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# preprocess title AKAs data\n",
    "def preprocess_dataframe_title_akas(data_frame):\n",
    "    title_akas_new_series=data_frame\n",
    "    title_akas_new_series=title_akas_new_series.drop(['types', 'attributes'],axis=1)\n",
    "    \n",
    "    title_akas_coerce_ordering = pd.to_numeric(title_akas_new_series['ordering'], errors='coerce')\n",
    "    title_akas_coerce_isOriginalTitle = pd.to_numeric(title_akas_new_series['isOriginalTitle'], errors='coerce')\n",
    "\n",
    "    df_1 = pd.DataFrame(dict(test_column_1 = title_akas_coerce_ordering)) \n",
    "    df_2 = pd.DataFrame(dict(test_column_2 = title_akas_coerce_isOriginalTitle)) \n",
    "\n",
    "    df_1['ordering'] = df_1['test_column_1']\n",
    "    df_2['isOriginalTitle'] = df_2['test_column_2']\n",
    "    \n",
    "    title_akas_new_frame=title_akas_new_series.drop(['ordering'],axis=1)\n",
    "    title_akas_new_frame=title_akas_new_series.drop(['isOriginalTitle'],axis=1)\n",
    "    \n",
    "    title_akas_new_frame['ordering']=df_1['ordering']\n",
    "    title_akas_new_frame['isOriginalTitle']=df_2['isOriginalTitle']\n",
    "    return title_akas_new_frame\n",
    "\n",
    "title_akas_preprocessed = preprocess_dataframe_title_akas(title_akas)\n",
    "title_akas_preprocessed[~title_akas_preprocessed.titleId.isin(title_basics_preprocessed.tconst)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_akas_preprocessed.titleId=title_akas_preprocessed.titleId.mask(~title_akas_preprocessed.titleId.isin(title_basics_preprocessed.tconst),None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|ââ        | 32/240 [01:03<06:47,  1.96s/it]"
     ]
    }
   ],
   "source": [
    "length = len(title_akas_preprocessed) // BATCH_SIZE + 1\n",
    "\n",
    "for chunk in tqdm(batch(title_akas_preprocessed, BATCH_SIZE), total = length):\n",
    "    # call helper function\n",
    "    load_dataframe(chunk, 'titleAKAs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Name Basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_basics = pd.read_csv('name.basics.tsv', delimiter='\\t',encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_dataframe_name_basics(data_frame):\n",
    "    name_basics_new_series=data_frame\n",
    "    name_basics_new_series=name_basics_new_series.drop(['primaryProfession', 'knownForTitles'],axis=1)\n",
    "    \n",
    "    name_basics_new_series['birthYear']= pd.to_datetime(name_basics_new_series.birthYear, errors='coerce', format='%Y')\n",
    "\n",
    "    #title_basics_new_frame_transpose['startYear']=[time.date() for time in title_basics_new_frame_transpose['startYear']]\n",
    "    \n",
    "    name_basics_new_series['deathYear']= pd.to_datetime(name_basics_new_series.deathYear, errors='coerce', format='%Y')\n",
    "    \n",
    "    return name_basics_new_series\n",
    "\n",
    "name_basics_preprocessed = preprocess_dataframe_name_basics(name_basics)\n",
    "\n",
    "name_basics_preprocessed[\"noofmovies\"] = \"\"\n",
    "name_basics_preprocessed[\"age\"] = \"\"\n",
    "name_basics_preprocessed[\"currentdate\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_basics_preprocessed_new = pd.to_numeric(name_basics_preprocessed['noofmovies'], errors = 'coerce')\n",
    "name_basics_preprocessed_new = pd.to_numeric(name_basics_preprocessed['age'], errors = 'coerce')\n",
    "name_basics_preprocessed['currentdate'] = pd.to_datetime(name_basics_preprocessed.currentdate, errors = 'coerce', format = '%Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = pd.DataFrame(dict(test_column_1 = name_basics_preprocessed_new)) \n",
    "df_2 = pd.DataFrame(dict(test_column_2 = name_basics_preprocessed_new)) \n",
    "\n",
    "df_1['noofmovies'] = df_1['test_column_1']\n",
    "df_2['age'] = df_2['test_column_2']\n",
    "\n",
    "name_basics_preprocessed['noofmovies'] = df_1['noofmovies']\n",
    "name_basics_preprocessed['age'] = df_2['age']\n",
    "name_basics_preprocessed['currentdate'] = pd.to_datetime(name_basics_preprocessed['currentdate'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approach 1- With sql alchemy ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "length = len(name_basics_preprocessed) // BATCH_SIZE +1\n",
    "\n",
    "for chunk in tqdm(batch(name_basics_preprocessed,BATCH_SIZE), total = length):\n",
    "    load_dataframe(chunk, 'namebasics')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNCOMMENT TO DISPLAY TABLE ROWS\n",
    "# mydb = mysql.connector.connect(\n",
    "#     host=\"localhost\",\n",
    "#     user=\"root\",\n",
    "#     passwd=\"alupizzo92\",\n",
    "#     database=\"imbd_application\"\n",
    "# )\n",
    "# mycursor = mydb.cursor()\n",
    "\n",
    "# query = \"SELECT * FROM namebasics LIMIT 5;\"\n",
    "# mycursor.execute(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Principals-will insert when nconst is in the right format  ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_principals = pd.read_csv('title.principals.tsv', delimiter = '\\t',encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Title crew ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_crew = pd.read_csv('title.crew.tsv', delimiter = '\\t',encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_crew_processed = title_crew.drop(['directors'], axis = 1)\n",
    "title_crew_processed = title_crew.drop(['writers'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "length = len(title_crew_processed) // BATCH_SIZE + 1\n",
    "\n",
    "for chunk in tqdm(batch(title_crew_processed, BATCH_SIZE), total = length):\n",
    "    load_dataframe(chunk,'titlecrew')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writers ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_dataframe_parsing(data_frame, column_name):\n",
    "    \n",
    "    data_frame = data_frame.to_frame()\n",
    "    data_frame = data_frame.assign(name = data_frame[column_name].str.split(\",\"))\n",
    "    #type(x.iloc[0,1])\n",
    "    data_frame = data_frame.explode('name')\n",
    "    \n",
    "    return data_frame\n",
    "writers_preprocessed = preprocess_dataframe_parsing(title_crew.writers, \"writers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "length = len(writers_preprocessed) // BATCH_SIZE + 1\n",
    "\n",
    "for chunk in tqdm(batch(writers_preprocessed, BATCH_SIZE), total = length):\n",
    "    load_dataframe(chunk, 'writers')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Directors ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directors_preprocessed = preprocess_dataframe_parsing(title_crew.directors, \"directors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "length = len(directors_preprocessed) // BATCH_SIZE + 1\n",
    "\n",
    "for chunk in tqdm(batch(directors_preprocessed, BATCH_SIZE), total = length):\n",
    "    # call helper function\n",
    "    load_dataframe(chunk, 'directors')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Genres ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genres_preprocessed = preprocess_dataframe_parsing(title_basics.genres, 'genres')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "length = len(genres_preprocessed) // BATCH_SIZE + 1\n",
    "\n",
    "for chunk in tqdm(batch(genres_preprocessed, BATCH_SIZE), total = length):\n",
    "    # call helper function\n",
    "    load_dataframe(chunk, 'genres')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Known for titles ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knownForTitles_preprocessed = preprocess_dataframe_parsing(name_basics.knownForTitles, 'knownForTitles')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "length = len(knownForTitles_preprocessed) // BATCH_SIZE + 1\n",
    "\n",
    "for chunk in tqdm(batch(knownForTitles_preprocessed, BATCH_SIZE), total = length):\n",
    "    # call helper function\n",
    "    load_dataframe(chunk, 'knownForTitles')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## primary profession ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprofession_preprocessed = preprocess_dataframe_parsing(name_basics.primaryProfession, 'primaryProfession')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "length = len(pprofession_preprocessed) // BATCH_SIZE + 1\n",
    "\n",
    "for chunk in tqdm(batch(pprofession_preprocessed, BATCH_SIZE), total = length):\n",
    "    # call helper function\n",
    "    load_dataframe(chunk, 'primaryProfession')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## types ## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "types_preprocessed = preprocess_dataframe_parsing(title_akas.types, 'types')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "length = len(types_preprocessed) // BATCH_SIZE + 1\n",
    "\n",
    "for chunk in tqdm(batch(types_preprocessed, BATCH_SIZE), total = length):\n",
    "    # call helper function\n",
    "    load_dataframe(chunk, 'types')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## attributes ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attributes_preprocessed = preprocess_dataframe_parsing(title_akas.attributes, 'attributes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "length = len(attributes_preprocessed) // BATCH_SIZE + 1\n",
    "\n",
    "for chunk in tqdm(batch(attributes_preprocessed, BATCH_SIZE), total = length):\n",
    "    load_dataframe(chunk, 'attributes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "batch_size=100000\n",
    "length=len(types_preprocessed)//batch_size+1\n",
    "for chunk in tqdm(batch(types_preprocessed,batch_size),total=length):\n",
    "    load_dataframe(chunk,'attributes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Characters ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_dataframe_parsing(data_frame, column_name):\n",
    "    \n",
    "    data_frame=data_frame.to_frame()\n",
    "    data_frame=data_frame.assign(=data_frame[column_name].str.replace('[\\[\\]\"]',\"\").str.split(\",\"))\n",
    "    #type(x.iloc[0,1])\n",
    "    data_frame=data_frame.explode('name')\n",
    "    \n",
    "    return data_frame\n",
    "characters_preprocessed=preprocess_dataframe_parsing(title_principals.characters, \"characters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "length = len(characters_preprocessed) // BATCH_SIZE + 1\n",
    "\n",
    "for chunk in tqdm(batch(directors_preprocessed, BATCH_SIZE), total = length):\n",
    "    load_dataframe(chunk, 'characters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
